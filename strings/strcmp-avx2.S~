#include "asm-common.h"


#ifndef ONE_PAGE
#define ONE_PAGE 0
#endif
#ifndef ALIGNMENT
#define ALIGNMENT 0
#endif
#ifndef PAGE_SIZE
#define PAGE_SIZE 4096
#endif
#ifndef VEC_SIZE
#define VEC_SIZE 32
#endif
#ifndef LOG_VEC_SIZE
#define LOG_VEC_SIZE 5
#endif

#if PAGE_SIZE != 4096 && PAGE_SIZE != 1048576
#error "PAGE_SIZE must be 4096 or 1048576"
#endif
#if VEC_SIZE != 32
#error "VEC_SIZE must be 32"
#endif
#if LOG_VEC_SIZE != 5
#error "VEC_SIZE must be 5"
#endif


    .file "strchr-avx2.S"
    .text

    // rdi = char * 
    // rsi = char *
START(strcmp_avx2):
    .cfi_startproc

    movl %edi, %ecx
    
    // ymm0 = 0s 
    vpxor %xmm0, %xmm0, %xmm0

    // cross page logic here

    // fall through not page crosses
    vmovdqu (%rdi), %ymm1
    vcmpeqb (%rsi), %ymm1, %ymm2
    vpminub %ymm1, %ymm2, %ymm1
    vpcmpeq %ymm1, %ymm0, %ymm1
    vptest %ymm1, %ymm1
    jnz L(YMM1_RET)

    // get diff for rdi till next vec alignment
    notq %ecx
    andl $(VEC_SIZE - 1), %ecx

    // align rdi
    addq %rcx, %rdi

    // increment rsi by same amount
    addq %rcx, %rsi

    testq $(4 * VEC_SIZE - 1), %rdi
    jz L(ALIGNED_VEC_SIZE_4x)

    movl %edi, %ecx
    andl $(4 * VEC_SIZE - 1), %ecx

    // aligned 96 
    cmpl $(3 * VEC_SIZE), %ecx
    jz L(ALIGNED_VEC_SIZE_3x)
    
    // aligned 64 
    cmpl $(2 * VEC_SIZE), %ecx
    jz L(ALIGNED_VEC_SIZE_2x)

    // 32 aligned
    vmovdqa (%rdi), %ymm1
    vcmpeqb (%rsi), %ymm1, %ymm2
    vpminub %ymm1, %ymm2, %ymm1
    vpcmpeq %ymm1, %ymm0, %ymm1
    vptest %ymm1, %ymm1
    jnz L(YMM1_RET)
    addq $(VEC_SIZE), %rdi
    addq $(VEC_SIZE), %rsi
    
L(ALIGNED_VEC_SIZE_2x):
    // 64 aligned
    vmovdqa (%rdi), %ymm1
    vcmpeqb (%rsi), %ymm1, %ymm2
    vpminub %ymm1, %ymm2, %ymm1
    vpcmpeq %ymm1, %ymm0, %ymm1
    vptest %ymm1, %ymm1
    jnz L(YMM1_RET)
    addq $(VEC_SIZE), %rdi
    addq $(VEC_SIZE), %rsi

L(ALIGNED_VEC_SIZE_3x):
    // 96 aligned
    vmovdqa (%rdi), %ymm1
    vcmpeqb (%rsi), %ymm1, %ymm2
    vpminub %ymm1, %ymm2, %ymm1
    vpcmpeq %ymm1, %ymm0, %ymm1
    vptest %ymm1, %ymm1
    jnz L(YMM1_RET)
    addq $(VEC_SIZE), %rdi
    addq $(VEC_SIZE), %rsi

L(PREP_4x_LOOP):
    movl $(PAGE_SIZE), %edx
    movl %esi, %ecx
    andl $(PAGE_SIZE - 1), %ecx
    subl %ecx, %edx
    sarl $(LOG_PAGE_SIZE), %edx

L(ALIGNED_VEC_SIZE_4x):
    
    
    

    .cfi_endproc
    END(strchr_avx2)
